{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6db31cc",
   "metadata": {
    "papermill": {
     "duration": 0.011583,
     "end_time": "2021-04-23T07:36:53.525434",
     "exception": false,
     "start_time": "2021-04-23T07:36:53.513851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd5a665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:36:53.563257Z",
     "iopub.status.busy": "2021-04-23T07:36:53.552241Z",
     "iopub.status.idle": "2021-04-23T07:37:46.999569Z",
     "shell.execute_reply": "2021-04-23T07:37:46.998890Z"
    },
    "papermill": {
     "duration": 53.463729,
     "end_time": "2021-04-23T07:37:46.999713",
     "exception": false,
     "start_time": "2021-04-23T07:36:53.535984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.15.0)\n",
      "Installing collected packages: Keras-Applications\n",
      "Successfully installed Keras-Applications-1.0.8\n",
      "Processing /kaggle/input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.18.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.4.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2021.3.17)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\n",
      "Installing collected packages: efficientnet\n",
      "Successfully installed efficientnet-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install '../input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl'\n",
    "!pip install '../input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a73753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:47.035138Z",
     "iopub.status.busy": "2021-04-23T07:37:47.034318Z",
     "iopub.status.idle": "2021-04-23T07:37:53.127545Z",
     "shell.execute_reply": "2021-04-23T07:37:53.127978Z"
    },
    "papermill": {
     "duration": 6.115274,
     "end_time": "2021-04-23T07:37:53.128226",
     "exception": false,
     "start_time": "2021-04-23T07:37:47.012952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import sklearn as sk\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gc\n",
    "import math\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c394084d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.175203Z",
     "iopub.status.busy": "2021-04-23T07:37:53.174311Z",
     "iopub.status.idle": "2021-04-23T07:37:53.176701Z",
     "shell.execute_reply": "2021-04-23T07:37:53.177313Z"
    },
    "papermill": {
     "duration": 0.028939,
     "end_time": "2021-04-23T07:37:53.177529",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.148590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = [512, 512]\n",
    "SEED = 42\n",
    "VERBOSE = 1\n",
    "N_CLASSES = 11014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6746988e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.223060Z",
     "iopub.status.busy": "2021-04-23T07:37:53.222394Z",
     "iopub.status.idle": "2021-04-23T07:37:53.225876Z",
     "shell.execute_reply": "2021-04-23T07:37:53.226620Z"
    },
    "papermill": {
     "duration": 0.028941,
     "end_time": "2021-04-23T07:37:53.226815",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.197874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GET_CV = False\n",
    "CHECK_SUB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e14165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.283964Z",
     "iopub.status.busy": "2021-04-23T07:37:53.282738Z",
     "iopub.status.idle": "2021-04-23T07:37:53.308711Z",
     "shell.execute_reply": "2021-04-23T07:37:53.307776Z"
    },
    "papermill": {
     "duration": 0.059381,
     "end_time": "2021-04-23T07:37:53.308846",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.249465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "# If we are comitting, replace train set for test set and dont get cv\n",
    "if len(df) > 3:\n",
    "    GET_CV = False\n",
    "del df\n",
    "\n",
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "# Function to read out dataset\n",
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        # Get train data from preprocess dataset (here we have our target ready)\n",
    "        df = pd.read_csv('../input/shopee-tf-records-512-stratified/train_folds.csv')\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "        \n",
    "    return df, image_paths\n",
    "\n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb95c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.372416Z",
     "iopub.status.busy": "2021-04-23T07:37:53.361770Z",
     "iopub.status.idle": "2021-04-23T07:37:53.378063Z",
     "shell.execute_reply": "2021-04-23T07:37:53.378736Z"
    },
    "papermill": {
     "duration": 0.04869,
     "end_time": "2021-04-23T07:37:53.378951",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.330261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115b9f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.436559Z",
     "iopub.status.busy": "2021-04-23T07:37:53.435559Z",
     "iopub.status.idle": "2021-04-23T07:37:53.440959Z",
     "shell.execute_reply": "2021-04-23T07:37:53.441929Z"
    },
    "papermill": {
     "duration": 0.041987,
     "end_time": "2021-04-23T07:37:53.442145",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.400158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings(image_paths):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "                n_classes = N_CLASSES, \n",
    "                s = 30, \n",
    "                m = 0.5, \n",
    "                name='head/arc_margin', \n",
    "                dtype='float32'\n",
    "                )\n",
    "        \n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB3(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights('../input/shopee/EfficientNetB3_224_42.h5')\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    \n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    \n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    \n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea9539e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.508338Z",
     "iopub.status.busy": "2021-04-23T07:37:53.507479Z",
     "iopub.status.idle": "2021-04-23T07:37:53.509645Z",
     "shell.execute_reply": "2021-04-23T07:37:53.509012Z"
    },
    "papermill": {
     "duration": 0.045577,
     "end_time": "2021-04-23T07:37:53.509784",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.464207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_embeddings(df, max_features = 15500):\n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df['title'])\n",
    "    print(f'Our title text embedding shape is {text_embeddings.shape}')\n",
    "    del model\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644bc1e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.569968Z",
     "iopub.status.busy": "2021-04-23T07:37:53.569252Z",
     "iopub.status.idle": "2021-04-23T07:37:53.576520Z",
     "shell.execute_reply": "2021-04-23T07:37:53.577428Z"
    },
    "papermill": {
     "duration": 0.043301,
     "end_time": "2021-04-23T07:37:53.577611",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.534310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neighbors(df, image_embeddings, text_embeddings, KNN = 50):\n",
    "    # Get distances and indices from image and text embeddings\n",
    "    neighbors_model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine').fit(image_embeddings)\n",
    "    image_distances, image_indices = neighbors_model.kneighbors(image_embeddings)\n",
    "    neighbors_model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine').fit(text_embeddings)\n",
    "    text_distances, text_indices = neighbors_model.kneighbors(text_embeddings)\n",
    "  \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if GET_CV:\n",
    "        predictions = []\n",
    "        for k in range(df.shape[0]):\n",
    "            # This are the original thresholds that gives 0.8035 cv (optimize with a for loop)\n",
    "            idx_image = np.where(image_distances[k,] < 0.46)[0]\n",
    "            ids_image = image_indices[k,idx_image]\n",
    "            idx_text = np.where(text_distances[k,] < 0.30)[0]\n",
    "            ids_text = text_indices[k,idx_text]\n",
    "            # Get the union of boths ids\n",
    "            ids = list(set(list(ids_image) + list(ids_text)))\n",
    "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "            predictions.append(posting_ids)\n",
    "    \n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in range(df.shape[0]):\n",
    "            # Reduce the thresholds because we are predicting more observations\n",
    "            idx_image = np.where(image_distances[k,] < 0.37)[0]\n",
    "            ids_image = image_indices[k,idx_image]\n",
    "            idx_text = np.where(text_distances[k,] < 0.21)[0]\n",
    "            ids_text = text_indices[k,idx_text]\n",
    "            # Get the union of boths ids\n",
    "            ids = list(set(list(ids_image) + list(ids_text)))\n",
    "            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    del neighbors_model, image_distances, image_indices, text_distances, text_indices\n",
    "    gc.collect()\n",
    "    return df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0329f2e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:37:53.632275Z",
     "iopub.status.busy": "2021-04-23T07:37:53.631427Z",
     "iopub.status.idle": "2021-04-23T07:38:08.191392Z",
     "shell.execute_reply": "2021-04-23T07:38:08.190419Z"
    },
    "papermill": {
     "duration": 14.590985,
     "end_time": "2021-04-23T07:38:08.191548",
     "exception": false,
     "start_time": "2021-04-23T07:37:53.600563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 1536)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, image_paths = read_dataset()\n",
    "\n",
    "image_embeddings = get_image_embeddings(image_paths)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0693737f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:38:08.236704Z",
     "iopub.status.busy": "2021-04-23T07:38:08.231564Z",
     "iopub.status.idle": "2021-04-23T07:38:08.241146Z",
     "shell.execute_reply": "2021-04-23T07:38:08.240680Z"
    },
    "papermill": {
     "duration": 0.034643,
     "end_time": "2021-04-23T07:38:08.241266",
     "exception": false,
     "start_time": "2021-04-23T07:38:08.206623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our title text embedding shape is (3, 26)\n"
     ]
    }
   ],
   "source": [
    "if GET_CV:\n",
    "    text_embeddings = get_text_embeddings(df, max_features = 15500)\n",
    "else:\n",
    "    text_embeddings = get_text_embeddings(df, max_features = 21500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48850cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:38:08.275053Z",
     "iopub.status.busy": "2021-04-23T07:38:08.274472Z",
     "iopub.status.idle": "2021-04-23T07:38:08.279038Z",
     "shell.execute_reply": "2021-04-23T07:38:08.278580Z"
    },
    "papermill": {
     "duration": 0.023719,
     "end_time": "2021-04-23T07:38:08.279170",
     "exception": false,
     "start_time": "2021-04-23T07:38:08.255451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "neighbours = 50\n",
    "if (len(df) <= 3):\n",
    "    neighbours = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cce601b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:38:08.314811Z",
     "iopub.status.busy": "2021-04-23T07:38:08.313930Z",
     "iopub.status.idle": "2021-04-23T07:38:08.471881Z",
     "shell.execute_reply": "2021-04-23T07:38:08.471378Z"
    },
    "papermill": {
     "duration": 0.178671,
     "end_time": "2021-04-23T07:38:08.472007",
     "exception": false,
     "start_time": "2021-04-23T07:38:08.293336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, predictions = get_neighbors(df, image_embeddings, text_embeddings, KNN = neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd52a8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T07:38:08.510408Z",
     "iopub.status.busy": "2021-04-23T07:38:08.509697Z",
     "iopub.status.idle": "2021-04-23T07:38:08.615062Z",
     "shell.execute_reply": "2021-04-23T07:38:08.614490Z"
    },
    "papermill": {
     "duration": 0.128529,
     "end_time": "2021-04-23T07:38:08.615208",
     "exception": false,
     "start_time": "2021-04-23T07:38:08.486679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['matches'] = predictions\n",
    "df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0816e",
   "metadata": {
    "papermill": {
     "duration": 0.014385,
     "end_time": "2021-04-23T07:38:08.644554",
     "exception": false,
     "start_time": "2021-04-23T07:38:08.630169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.701505,
   "end_time": "2021-04-23T07:38:10.974615",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-23T07:36:48.273110",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
