{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.18.1)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 733 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.4.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.5.4)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2021.3.17)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
      "Installing collected packages: keras-applications, efficientnet\n",
      "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import sklearn as sk\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gc\n",
    "import math\n",
    "import re\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.4.1\n",
      "Keras Version: 2.4.0\n",
      "Python 3.7.9 | packaged by conda-forge | (default, Feb 13 2021, 20:03:11) \n",
      "[GCC 9.3.0]\n",
      "Pandas 1.1.5\n",
      "Scikit-Learn 0.24.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = [224, 224]\n",
    "SEED = 42\n",
    "LR = 0.001\n",
    "VERBOSE = 1\n",
    "N_CLASSES = 11014\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224, 224]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/shopee-tf-records-512-stratified/train02-2284.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train08-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train10-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train05-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train01-2284.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train12-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train09-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train07-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train00-2284.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train06-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train03-2284.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train11-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train04-2284.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train13-2283.tfrec',\n",
       " '../input/shopee-tf-records-512-stratified/train14-2283.tfrec']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_FILENAMES = tf.io.gfile.glob('../input/shopee-tf-records-512-stratified' + '/*.tfrec')\n",
    "TRAINING_FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arcface_format(posting_id, image, label_group, matches):\n",
    "    return posting_id, {'inp1': image, 'inp2': label_group}, label_group, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(posting_id, image, label_group, matches):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_hue(image, 0.01)\n",
    "    image = tf.image.random_saturation(image, 0.70, 1.30)\n",
    "    image = tf.image.random_contrast(image, 0.80, 1.20)\n",
    "    image = tf.image.random_brightness(image, 0.10)\n",
    "    return posting_id, image, label_group, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"posting_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label_group\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"matches\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    posting_id = example['posting_id']\n",
    "    image = decode_image(example['image'])\n",
    "    label_group = tf.cast(example['label_group'], tf.int32)\n",
    "    matches = example['matches']\n",
    "    return posting_id, image, label_group, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, ordered = False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset(filenames, ordered = False):\n",
    "    dataset = load_dataset(filenames, ordered = ordered)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_dataset(filenames, ordered = True):\n",
    "    dataset = load_dataset(filenames, ordered = ordered)\n",
    "    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 34250 training images\n"
     ]
    }
   ],
   "source": [
    "def count_data_items(filenames):\n",
    "    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "print(f'Dataset: {NUM_TRAINING_IMAGES} training images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback():\n",
    "    lr_start   = 0.000001\n",
    "    lr_max     = 0.000005 * BATCH_SIZE\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max    \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    with strategy.scope():\n",
    "        margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "        x = efn.EfficientNetB3(weights = 'imagenet', include_top = False)(inp)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = margin([x, label])\n",
    "        \n",
    "        output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "        \n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = opt,\n",
    "            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "            metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "            ) \n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(intial_ep = 0, epoch = 20):\n",
    "\n",
    "    # Seed everything\n",
    "    seed_everything(SEED)\n",
    "    train, valid = train_test_split(TRAINING_FILENAMES, shuffle = True, random_state = SEED)\n",
    "    train_dataset = get_training_dataset(train, ordered = False)\n",
    "    train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "    val_dataset = get_validation_dataset(valid, ordered = True)\n",
    "    val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "    STEPS_PER_EPOCH = count_data_items(train) // BATCH_SIZE\n",
    "    K.clear_session()\n",
    "    model = get_model()\n",
    "#     model.load_weights('../input/shopee/EfficientNetB3_224_42_score_0.71.h5')\n",
    "    model.summary()\n",
    "    \n",
    "    # Model checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'EfficientNetB3_{IMAGE_SIZE[0]}_{SEED}.h5', \n",
    "                                                    monitor = 'val_loss', \n",
    "                                                    verbose = VERBOSE, \n",
    "                                                    save_best_only = True,\n",
    "                                                    save_weights_only = True, \n",
    "                                                    mode = 'min')\n",
    "\n",
    "    history = model.fit(train_dataset,\n",
    "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                        initial_epoch=intial_ep,\n",
    "                        epochs = epoch,\n",
    "                        callbacks = [checkpoint, get_lr_callback()], \n",
    "                        validation_data = val_dataset,\n",
    "                        verbose = VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "44113920/44107200 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp1 (InputLayer)               [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b3 (Functional)    (None, None, None, 1 10783528    inp1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1536)         0           efficientnet-b3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inp2 (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head/arc_margin (ArcMarginProdu (None, 11014)        16917504    global_average_pooling2d[0][0]   \n",
      "                                                                 inp2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 11014)        0           head/arc_margin[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 27,701,032\n",
      "Trainable params: 27,613,736\n",
      "Non-trainable params: 87,296\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n",
      "784/784 [==============================] - 357s 423ms/step - loss: 23.9511 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.9180 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 23.91798, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 2/40\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.28e-05.\n",
      "784/784 [==============================] - 329s 420ms/step - loss: 23.5919 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.7641 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 23.91798 to 22.76406, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 3/40\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.46e-05.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 21.9969 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 20.4819 - val_sparse_categorical_accuracy: 7.6645e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 22.76406 to 20.48186, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 4/40\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.64e-05.\n",
      "784/784 [==============================] - 325s 414ms/step - loss: 19.3083 - sparse_categorical_accuracy: 0.0015 - val_loss: 17.7256 - val_sparse_categorical_accuracy: 0.0218\n",
      "\n",
      "Epoch 00004: val_loss improved from 20.48186 to 17.72559, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 5/40\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0001282.\n",
      "784/784 [==============================] - 325s 414ms/step - loss: 16.0464 - sparse_categorical_accuracy: 0.0228 - val_loss: 15.3160 - val_sparse_categorical_accuracy: 0.0787\n",
      "\n",
      "Epoch 00005: val_loss improved from 17.72559 to 15.31602, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 6/40\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00016.\n",
      "784/784 [==============================] - 328s 418ms/step - loss: 12.9282 - sparse_categorical_accuracy: 0.0721 - val_loss: 13.3650 - val_sparse_categorical_accuracy: 0.1514\n",
      "\n",
      "Epoch 00006: val_loss improved from 15.31602 to 13.36496, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 7/40\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00012820000000000003.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 9.7911 - sparse_categorical_accuracy: 0.1507 - val_loss: 12.1445 - val_sparse_categorical_accuracy: 0.2091\n",
      "\n",
      "Epoch 00007: val_loss improved from 13.36496 to 12.14452, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 8/40\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00010276000000000003.\n",
      "784/784 [==============================] - 322s 411ms/step - loss: 7.5887 - sparse_categorical_accuracy: 0.2405 - val_loss: 11.3502 - val_sparse_categorical_accuracy: 0.2457\n",
      "\n",
      "Epoch 00008: val_loss improved from 12.14452 to 11.35017, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 9/40\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 8.240800000000003e-05.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 6.0033 - sparse_categorical_accuracy: 0.3296 - val_loss: 10.8121 - val_sparse_categorical_accuracy: 0.2738\n",
      "\n",
      "Epoch 00009: val_loss improved from 11.35017 to 10.81208, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 10/40\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 6.612640000000001e-05.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 4.9363 - sparse_categorical_accuracy: 0.3951 - val_loss: 10.4512 - val_sparse_categorical_accuracy: 0.3017\n",
      "\n",
      "Epoch 00010: val_loss improved from 10.81208 to 10.45124, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 11/40\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 5.3101120000000014e-05.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 4.2146 - sparse_categorical_accuracy: 0.4409 - val_loss: 10.1885 - val_sparse_categorical_accuracy: 0.3284\n",
      "\n",
      "Epoch 00011: val_loss improved from 10.45124 to 10.18854, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 12/40\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 4.2680896000000016e-05.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 3.6300 - sparse_categorical_accuracy: 0.4942 - val_loss: 9.9981 - val_sparse_categorical_accuracy: 0.3516\n",
      "\n",
      "Epoch 00012: val_loss improved from 10.18854 to 9.99809, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 13/40\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 3.4344716800000014e-05.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 3.2212 - sparse_categorical_accuracy: 0.5430 - val_loss: 9.8484 - val_sparse_categorical_accuracy: 0.3645\n",
      "\n",
      "Epoch 00013: val_loss improved from 9.99809 to 9.84841, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 14/40\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 2.7675773440000016e-05.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 2.8934 - sparse_categorical_accuracy: 0.5843 - val_loss: 9.7493 - val_sparse_categorical_accuracy: 0.3760\n",
      "\n",
      "Epoch 00014: val_loss improved from 9.84841 to 9.74934, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 15/40\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 2.234061875200001e-05.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 2.6080 - sparse_categorical_accuracy: 0.6263 - val_loss: 9.6749 - val_sparse_categorical_accuracy: 0.3826\n",
      "\n",
      "Epoch 00015: val_loss improved from 9.74934 to 9.67492, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 16/40\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.807249500160001e-05.\n",
      "784/784 [==============================] - 329s 420ms/step - loss: 2.4743 - sparse_categorical_accuracy: 0.6482 - val_loss: 9.6117 - val_sparse_categorical_accuracy: 0.3892\n",
      "\n",
      "Epoch 00016: val_loss improved from 9.67492 to 9.61166, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 17/40\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.465799600128001e-05.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 2.3244 - sparse_categorical_accuracy: 0.6692 - val_loss: 9.5687 - val_sparse_categorical_accuracy: 0.3942\n",
      "\n",
      "Epoch 00017: val_loss improved from 9.61166 to 9.56871, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 18/40\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.1926396801024009e-05.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 2.1911 - sparse_categorical_accuracy: 0.6896 - val_loss: 9.5363 - val_sparse_categorical_accuracy: 0.3971\n",
      "\n",
      "Epoch 00018: val_loss improved from 9.56871 to 9.53634, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 19/40\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 9.741117440819207e-06.\n",
      "784/784 [==============================] - 330s 420ms/step - loss: 2.1399 - sparse_categorical_accuracy: 0.6974 - val_loss: 9.5071 - val_sparse_categorical_accuracy: 0.3994\n",
      "\n",
      "Epoch 00019: val_loss improved from 9.53634 to 9.50711, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 20/40\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 7.992893952655366e-06.\n",
      "784/784 [==============================] - 326s 415ms/step - loss: 2.0607 - sparse_categorical_accuracy: 0.7142 - val_loss: 9.4887 - val_sparse_categorical_accuracy: 0.4011\n",
      "\n",
      "Epoch 00020: val_loss improved from 9.50711 to 9.48865, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 21/40\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 6.594315162124293e-06.\n",
      "784/784 [==============================] - 329s 420ms/step - loss: 2.0236 - sparse_categorical_accuracy: 0.7155 - val_loss: 9.4715 - val_sparse_categorical_accuracy: 0.4026\n",
      "\n",
      "Epoch 00021: val_loss improved from 9.48865 to 9.47149, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 22/40\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 5.475452129699435e-06.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 1.9114 - sparse_categorical_accuracy: 0.7353 - val_loss: 9.4576 - val_sparse_categorical_accuracy: 0.4035\n",
      "\n",
      "Epoch 00022: val_loss improved from 9.47149 to 9.45760, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 23/40\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 4.580361703759548e-06.\n",
      "784/784 [==============================] - 325s 415ms/step - loss: 1.8943 - sparse_categorical_accuracy: 0.7391 - val_loss: 9.4473 - val_sparse_categorical_accuracy: 0.4053\n",
      "\n",
      "Epoch 00023: val_loss improved from 9.45760 to 9.44734, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 24/40\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 3.864289363007639e-06.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 1.8786 - sparse_categorical_accuracy: 0.7445 - val_loss: 9.4392 - val_sparse_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00024: val_loss improved from 9.44734 to 9.43922, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 25/40\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 3.291431490406111e-06.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 1.8344 - sparse_categorical_accuracy: 0.7450 - val_loss: 9.4326 - val_sparse_categorical_accuracy: 0.4071\n",
      "\n",
      "Epoch 00025: val_loss improved from 9.43922 to 9.43263, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 26/40\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 2.833145192324889e-06.\n",
      "784/784 [==============================] - 328s 419ms/step - loss: 1.8235 - sparse_categorical_accuracy: 0.7505 - val_loss: 9.4278 - val_sparse_categorical_accuracy: 0.4078\n",
      "\n",
      "Epoch 00026: val_loss improved from 9.43263 to 9.42782, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 27/40\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 2.4665161538599113e-06.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 1.7876 - sparse_categorical_accuracy: 0.7541 - val_loss: 9.4211 - val_sparse_categorical_accuracy: 0.4080\n",
      "\n",
      "Epoch 00027: val_loss improved from 9.42782 to 9.42107, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 28/40\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 2.173212923087929e-06.\n",
      "784/784 [==============================] - 328s 419ms/step - loss: 1.7778 - sparse_categorical_accuracy: 0.7598 - val_loss: 9.4156 - val_sparse_categorical_accuracy: 0.4082\n",
      "\n",
      "Epoch 00028: val_loss improved from 9.42107 to 9.41562, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 29/40\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.938570338470343e-06.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 1.7706 - sparse_categorical_accuracy: 0.7585 - val_loss: 9.4112 - val_sparse_categorical_accuracy: 0.4085\n",
      "\n",
      "Epoch 00029: val_loss improved from 9.41562 to 9.41116, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 30/40\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.7508562707762748e-06.\n",
      "784/784 [==============================] - 324s 414ms/step - loss: 1.7475 - sparse_categorical_accuracy: 0.7580 - val_loss: 9.4091 - val_sparse_categorical_accuracy: 0.4092\n",
      "\n",
      "Epoch 00030: val_loss improved from 9.41116 to 9.40908, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 31/40\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 1.6006850166210196e-06.\n",
      "784/784 [==============================] - 326s 416ms/step - loss: 1.7684 - sparse_categorical_accuracy: 0.7569 - val_loss: 9.4037 - val_sparse_categorical_accuracy: 0.4092\n",
      "\n",
      "Epoch 00031: val_loss improved from 9.40908 to 9.40371, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 32/40\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1.4805480132968159e-06.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 1.7490 - sparse_categorical_accuracy: 0.7609 - val_loss: 9.4030 - val_sparse_categorical_accuracy: 0.4091\n",
      "\n",
      "Epoch 00032: val_loss improved from 9.40371 to 9.40296, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 33/40\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 1.3844384106374527e-06.\n",
      "784/784 [==============================] - 328s 418ms/step - loss: 1.7269 - sparse_categorical_accuracy: 0.7651 - val_loss: 9.4012 - val_sparse_categorical_accuracy: 0.4090\n",
      "\n",
      "Epoch 00033: val_loss improved from 9.40296 to 9.40121, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 34/40\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 1.307550728509962e-06.\n",
      "784/784 [==============================] - 330s 421ms/step - loss: 1.7303 - sparse_categorical_accuracy: 0.7636 - val_loss: 9.3982 - val_sparse_categorical_accuracy: 0.4098\n",
      "\n",
      "Epoch 00034: val_loss improved from 9.40121 to 9.39819, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 35/40\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 1.2460405828079697e-06.\n",
      "784/784 [==============================] - 325s 415ms/step - loss: 1.7519 - sparse_categorical_accuracy: 0.7611 - val_loss: 9.3947 - val_sparse_categorical_accuracy: 0.4093\n",
      "\n",
      "Epoch 00035: val_loss improved from 9.39819 to 9.39473, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 36/40\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 1.1968324662463758e-06.\n",
      "784/784 [==============================] - 327s 418ms/step - loss: 1.7088 - sparse_categorical_accuracy: 0.7705 - val_loss: 9.3952 - val_sparse_categorical_accuracy: 0.4099\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 9.39473\n",
      "Epoch 37/40\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.1574659729971007e-06.\n",
      "784/784 [==============================] - 327s 418ms/step - loss: 1.7114 - sparse_categorical_accuracy: 0.7671 - val_loss: 9.3917 - val_sparse_categorical_accuracy: 0.4101\n",
      "\n",
      "Epoch 00037: val_loss improved from 9.39473 to 9.39165, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 38/40\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.1259727783976805e-06.\n",
      "784/784 [==============================] - 328s 418ms/step - loss: 1.7063 - sparse_categorical_accuracy: 0.7687 - val_loss: 9.3882 - val_sparse_categorical_accuracy: 0.4102\n",
      "\n",
      "Epoch 00038: val_loss improved from 9.39165 to 9.38822, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 39/40\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.1007782227181443e-06.\n",
      "784/784 [==============================] - 327s 418ms/step - loss: 1.6859 - sparse_categorical_accuracy: 0.7737 - val_loss: 9.3867 - val_sparse_categorical_accuracy: 0.4105\n",
      "\n",
      "Epoch 00039: val_loss improved from 9.38822 to 9.38667, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 40/40\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 1.0806225781745155e-06.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 1.6558 - sparse_categorical_accuracy: 0.7763 - val_loss: 9.3849 - val_sparse_categorical_accuracy: 0.4108\n",
      "\n",
      "Epoch 00040: val_loss improved from 9.38667 to 9.38492, saving model to EfficientNetB3_224_42.h5\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp1 (InputLayer)               [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b3 (Functional)    (None, None, None, 1 10783528    inp1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1536)         0           efficientnet-b3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inp2 (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head/arc_margin (ArcMarginProdu (None, 11014)        16917504    global_average_pooling2d_1[0][0] \n",
      "                                                                 inp2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 11014)        0           head/arc_margin[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 27,701,032\n",
      "Trainable params: 27,613,736\n",
      "Non-trainable params: 87,296\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 1.0644980625396124e-06.\n",
      "784/784 [==============================] - 353s 423ms/step - loss: 1.6555 - sparse_categorical_accuracy: 0.7781 - val_loss: 9.3849 - val_sparse_categorical_accuracy: 0.4109\n",
      "\n",
      "Epoch 00041: val_loss improved from inf to 9.38493, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 1.05159845003169e-06.\n",
      "784/784 [==============================] - 331s 423ms/step - loss: 1.6369 - sparse_categorical_accuracy: 0.7775 - val_loss: 9.3851 - val_sparse_categorical_accuracy: 0.4107\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 9.38493\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 1.0412787600253518e-06.\n",
      "784/784 [==============================] - 329s 420ms/step - loss: 1.6340 - sparse_categorical_accuracy: 0.7786 - val_loss: 9.3821 - val_sparse_categorical_accuracy: 0.4109\n",
      "\n",
      "Epoch 00043: val_loss improved from 9.38493 to 9.38208, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 1.0330230080202815e-06.\n",
      "784/784 [==============================] - 331s 422ms/step - loss: 1.5493 - sparse_categorical_accuracy: 0.7926 - val_loss: 9.3803 - val_sparse_categorical_accuracy: 0.4116\n",
      "\n",
      "Epoch 00044: val_loss improved from 9.38208 to 9.38031, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 1.0264184064162253e-06.\n",
      "784/784 [==============================] - 333s 425ms/step - loss: 1.5242 - sparse_categorical_accuracy: 0.7956 - val_loss: 9.3804 - val_sparse_categorical_accuracy: 0.4114\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 9.38031\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1.02113472513298e-06.\n",
      "784/784 [==============================] - 327s 417ms/step - loss: 1.4767 - sparse_categorical_accuracy: 0.8005 - val_loss: 9.3778 - val_sparse_categorical_accuracy: 0.4111\n",
      "\n",
      "Epoch 00046: val_loss improved from 9.38031 to 9.37785, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1.0169077801063842e-06.\n",
      "784/784 [==============================] - 328s 418ms/step - loss: 1.4571 - sparse_categorical_accuracy: 0.8066 - val_loss: 9.3756 - val_sparse_categorical_accuracy: 0.4115\n",
      "\n",
      "Epoch 00047: val_loss improved from 9.37785 to 9.37562, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1.0135262240851073e-06.\n",
      "784/784 [==============================] - 327s 418ms/step - loss: 1.4703 - sparse_categorical_accuracy: 0.8072 - val_loss: 9.3742 - val_sparse_categorical_accuracy: 0.4119\n",
      "\n",
      "Epoch 00048: val_loss improved from 9.37562 to 9.37423, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 1.0108209792680858e-06.\n",
      "784/784 [==============================] - 329s 420ms/step - loss: 1.4569 - sparse_categorical_accuracy: 0.8085 - val_loss: 9.3721 - val_sparse_categorical_accuracy: 0.4120\n",
      "\n",
      "Epoch 00049: val_loss improved from 9.37423 to 9.37206, saving model to EfficientNetB3_224_42.h5\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 1.0086567834144687e-06.\n",
      "784/784 [==============================] - 327s 418ms/step - loss: 1.5126 - sparse_categorical_accuracy: 0.7966 - val_loss: 9.3700 - val_sparse_categorical_accuracy: 0.4120\n",
      "\n",
      "Epoch 00050: val_loss improved from 9.37206 to 9.37002, saving model to EfficientNetB3_224_42.h5\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(intial_ep = 0, epoch = 20):\n",
    "    # Seed everything\n",
    "    seed_everything(SEED)\n",
    "    train, valid = train_test_split(TRAINING_FILENAMES, shuffle = True, random_state = SEED)\n",
    "    train_dataset = get_training_dataset(train, ordered = False)\n",
    "    train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "    val_dataset = get_validation_dataset(valid, ordered = True)\n",
    "    val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "    STEPS_PER_EPOCH = count_data_items(train) // BATCH_SIZE\n",
    "    model = get_model()\n",
    "    model.load_weights('./EfficientNetB3_224_42.h5')\n",
    "    model.summary()\n",
    "    \n",
    "    # Model checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'EfficientNetB3_{IMAGE_SIZE[0]}_{SEED}.h5', \n",
    "                                                    monitor = 'val_loss', \n",
    "                                                    verbose = VERBOSE, \n",
    "                                                    save_best_only = True,\n",
    "                                                    save_weights_only = True, \n",
    "                                                    mode = 'min')\n",
    "\n",
    "    history = model.fit(train_dataset,\n",
    "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                        initial_epoch=intial_ep,\n",
    "                        epochs = epoch,\n",
    "                        callbacks = [checkpoint, get_lr_callback()], \n",
    "                        validation_data = val_dataset,\n",
    "                        verbose = VERBOSE)\n",
    "\n",
    "train_and_evaluate(40, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
