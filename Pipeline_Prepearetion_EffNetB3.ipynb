{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a2fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import sklearn as sk\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gc\n",
    "import math\n",
    "import re\n",
    "import joblib\n",
    "import scipy.sparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75287baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = [512, 512]\n",
    "SEED = 42\n",
    "VERBOSE = 1\n",
    "N_CLASSES = 11014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01edf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_CV = True\n",
    "CHECK_SUB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92bc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read out dataset\n",
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        # Get train data from preprocess dataset (here we have our target ready)\n",
    "        df = pd.read_csv('../Dataset/train.csv')\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        image_paths = '../Dataset/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../Dataset/test.csv')\n",
    "        image_paths = '../Dataset/test_images/' + df['image']\n",
    "        \n",
    "    return df, image_paths\n",
    "\n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21161908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "131e9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embeddings(image_paths):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "                n_classes = N_CLASSES, \n",
    "                s = 30, \n",
    "                m = 0.5, \n",
    "                name='head/arc_margin', \n",
    "                dtype='float32'\n",
    "                )\n",
    "        \n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB3(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights('../EffNetB1_Weights/EfficientNetB3_224_42.h5')\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    \n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    \n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    \n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    \n",
    "    return model, image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44ad9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embeddings(df, max_features = 15500):\n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    fitted_tfidf = model.fit(df['title'])\n",
    "    text_embeddings = model.transform(df['title'])\n",
    "    del model\n",
    "    return fitted_tfidf, text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65a6fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, image_paths = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72d9789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp1 (InputLayer)               [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b3 (Functional)    (None, None, None, 1 10783528    inp1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 1536)         0           efficientnet-b3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inp2 (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head/arc_margin (ArcMarginProdu (None, 11014)        16917504    global_average_pooling2d_3[0][0] \n",
      "                                                                 inp2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "softmax_3 (Softmax)             (None, 11014)        0           head/arc_margin[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 27,701,032\n",
      "Trainable params: 27,613,736\n",
      "Non-trainable params: 87,296\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inp1 (InputLayer)            [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b3 (Functional) (None, None, None, 1536)  10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1536)              0         \n",
      "=================================================================\n",
      "Total params: 10,783,528\n",
      "Trainable params: 10,696,232\n",
      "Non-trainable params: 87,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, image_embeddings = get_image_embeddings(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "626869ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inp1 (InputLayer)            [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b3 (Functional) (None, None, None, 1536)  10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1536)              0         \n",
      "=================================================================\n",
      "Total params: 10,783,528\n",
      "Trainable params: 10,696,232\n",
      "Non-trainable params: 87,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d12c7afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: effnetb3_model_tf\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('effnetb3_model_tf', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('image_embeddings', image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be579ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf, title_embeddings = get_text_embeddings(df, max_features = 21500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8a48d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title_tfidf.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf, 'title_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9aac8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('title_embeddings.npz', title_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae035e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08faeab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea41a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fde70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
